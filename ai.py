import os
os.system("pip install scikit-learn")
os.system("pip install tensorflow")
os.system("pip install tensorflow-cpu")
import random
import threading
import time
from collections import Counter, deque
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import LSTM, Dense, Dropout
from keras.callbacks import ModelCheckpoint
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import ApplicationBuilder, CommandHandler, CallbackQueryHandler, ContextTypes
import numpy as np

# Token bot Telegram
TOKEN = os.getenv("TELEGRAM_TOKEN")
if not TOKEN:
    raise ValueError("Vui l√≤ng ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng TELEGRAM_TOKEN ch·ª©a token bot!")

# B·ªô nh·ªõ l·ªãch s·ª≠
history_data = deque(maxlen=400)  # L∆∞u t·ªëi ƒëa 100 k·∫øt qu·∫£ T√†i/X·ªâu
dice_data = deque(maxlen=400)     # L∆∞u t·ªëi ƒëa 100 k·∫øt qu·∫£ s√∫c s·∫Øc

# ==============================
# C√°c m√¥ h√¨nh h·ªçc m√°y
# ==============================
def save_data():
    np.save("history_data.npy", np.array(history_data))
    np.save("dice_data.npy", np.array(dice_data))
    
def load_data():
    global history_data, dice_data
    try:
        if os.path.exists("history_data.npy"):
            history_data.extend(np.load("history_data.npy").tolist())
        if os.path.exists("dice_data.npy"):
            dice_data.extend(np.load("dice_data.npy").tolist())
    except Exception as e:
        print(f"L·ªói khi t·∫£i d·ªØ li·ªáu: {e}")
        
def prepare_lstm_data(data, sequence_length=10):
    X, y = [], []
    for i in range(len(data) - sequence_length):
        X.append(data[i:i + sequence_length])
        y.append(data[i + sequence_length])  # Gi√° tr·ªã ti·∫øp theo l√† nh√£n
    X = np.array(X)
    y = np.array(y)
    return X, y
    
#kh·ªüi t·∫°o m√¥ h√¨nh
nb_model = GaussianNB()
lr_model = LogisticRegression()
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
scaler = MinMaxScaler(feature_range=(0, 1))

def build_lstm_model(input_shape):
    model = Sequential()
    model.add(LSTM(50, input_shape=input_shape, return_sequences=True))
    model.add(Dropout(0.2))
    model.add(LSTM(50))
    model.add(Dropout(0.2))
    model.add(Dense(1, activation="sigmoid"))
    model.compile(optimizer="adam", loss="binary_crossentropy", metrics=["accuracy"])
    return model

lstm_checkpoint = ModelCheckpoint(
    "lstm_best_model.keras",  # Thay ƒë·ªïi ƒëu√¥i th√†nh .keras
    monitor="loss",
    save_best_only=True,
    verbose=1
)

# Sau khi hu·∫•n luy·ªán xong, m√¥ h√¨nh s·∫Ω t·ª± ƒë·ªông l∆∞u v√†o "lstm_best_model.keras"
# ==============================
# C√°c h√†m h·ªó tr·ª£
# ==============================

def detect_pattern(history):
    if len(history) < 4:
        return "Kh√¥ng ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√°t hi·ªán c·∫ßu."

    # Ph√°t hi·ªán c·∫ßu 1-1 (T√†i, X·ªâu xen k·∫Ω)
    is_one_one = all(history[i] != history[i + 1] for i in range(len(history) - 1))
    if is_one_one:
        return "C·∫ßu 1-1: T√†i, X·ªâu xen k·∫Ω."

    # Ph√°t hi·ªán c·∫ßu b·ªát (chu·ªói l·∫∑p l·∫°i c√πng lo·∫°i)
    is_bet = all(history[i] == history[i + 1] for i in range(len(history) - 1))
    if is_bet:
        return f"C·∫ßu b·ªát: {history[0]} l·∫∑p l·∫°i."

    return "Kh√¥ng ph√°t hi·ªán c·∫ßu r√µ r√†ng."
    
def combined_prediction(history, dice_values):
    """
    K·∫øt h·ª£p d·ª± ƒëo√°n t·ª´ l·ªãch s·ª≠ v√† t·ªïng s√∫c s·∫Øc.
    """
    # N·∫øu l·ªãch s·ª≠ r·ªóng, tr·∫£ v·ªÅ d·ª± ƒëo√°n ng·∫´u nhi√™n
    if not history:
        prediction = random.choice(["t", "x"])
        prob_tai = prob_xiu = 50.0
    else:
        # T√≠nh tr·ªçng s·ªë cho l·ªãch s·ª≠
        weights = [0.8**i for i in range(len(history))]
        counter = {"t": 0, "x": 0}

        for i, result in enumerate(history):
            counter[result] += weights[i]

        total_weight = sum(weights)
        prob_tai = (counter["t"] / total_weight) * 100
        prob_xiu = (counter["x"] / total_weight) * 100

        # D·ª± ƒëo√°n d·ª±a tr√™n l·ªãch s·ª≠
        prediction = "t" if prob_tai > prob_xiu else "x"

    # T√≠nh t·ªïng ƒëi·ªÉm t·ª´ d·ªØ li·ªáu x√∫c x·∫Øc
    total_points = sum(dice_values) if dice_values else 0
    dice_prediction = "t" if total_points % 2 == 0 else "x"

    # K·∫øt h·ª£p d·ª± ƒëo√°n t·ª´ l·ªãch s·ª≠ v√† d·ªØ li·ªáu x√∫c x·∫Øc
    final_prediction = prediction if prediction == dice_prediction else dice_prediction

    return final_prediction, prob_tai, prob_xiu

def optimize_hyperparameters(history_data, dice_data, labels):
    # K·∫øt h·ª£p d·ªØ li·ªáu l·ªãch s·ª≠ v√† x√∫c x·∫Øc th√†nh m·ªôt t·∫≠p h·ª£p
    X_combined = np.array([history_data + dice_data])
    y_combined = np.array(labels)

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_combined)

    # T·ªëi ∆∞u Random Forest
    rf_params = {'n_estimators': [100, 200, 300], 'max_depth': [None, 10, 20]}
    grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), rf_params, cv=3, scoring='accuracy')
    grid_rf.fit(X_scaled, y_combined)
    print("Best Random Forest Params:", grid_rf.best_params_)

    # T·ªëi ∆∞u Logistic Regression
    lr_params = {'C': [0.01, 0.1, 1, 10]}
    grid_lr = GridSearchCV(LogisticRegression(max_iter=1000), lr_params, cv=3, scoring='accuracy')
    grid_lr.fit(X_scaled, y_combined)
    print("Best Logistic Regression Params:", grid_lr.best_params_)

    return grid_rf.best_params_, grid_lr.best_params_
    
def train_models(history_data, dice_data):
    try:
        # Chuy·ªÉn d·ªØ li·ªáu T√†i/X·ªâu th√†nh nh√£n
        history_labels = [1 if result == "t" else 0 for result in history_data]

        # T·∫°o d·ªØ li·ªáu ƒë·∫∑c tr∆∞ng: ch·ªâ s·ªë + t·ªïng gi√° tr·ªã + ch·∫µn/l·∫ª
        X_features = []
        for i in range(len(history_data)):
            total = sum(dice_data[max(0, i - 3):i + 1])  # T·ªïng c·ªßa 4 gi√° tr·ªã g·∫ßn nh·∫•t
            even_odd = total % 2  # Ch·∫µn/l·∫ª
            X_features.append([i, total, even_odd])

        X_features = np.array(X_features)

        # Chu·∫©n h√≥a d·ªØ li·ªáu
        X_scaled = scaler.fit_transform(X_features)

        # Hu·∫•n luy·ªán Naive Bayes
        nb_model.fit(X_scaled, history_labels)

        # Hu·∫•n luy·ªán Logistic Regression
        lr_model.fit(X_scaled, history_labels)

        # Hu·∫•n luy·ªán Random Forest
        rf_model.fit(X_scaled, history_labels)

        # Hu·∫•n luy·ªán LSTM n·∫øu ƒë·ªß d·ªØ li·ªáu
        if len(history_data) > 10:
            X_lstm = X_scaled.reshape((X_scaled.shape[0], X_scaled.shape[1], 1))
            lstm_model = build_lstm_model((X_lstm.shape[1], 1))
            lstm_model.fit(X_lstm, history_labels, epochs=10, batch_size=1, verbose=0)

        print("Hu·∫•n luy·ªán m√¥ h√¨nh th√†nh c√¥ng!")
    except Exception as e:
        print(f"L·ªói khi hu·∫•n luy·ªán m√¥ h√¨nh: {e}")

# H√†m d·ª± ƒëo√°n t·ª´ nhi·ªÅu m√¥ h√¨nh
def predict_combined(dice_values, history):
    try:
        # Ki·ªÉm tra d·ªØ li·ªáu ƒë·∫ßu v√†o
        validate_input_data(dice_values)

        # T√≠nh t·ªïng, ch·∫µn/l·∫ª t·ª´ x√∫c x·∫Øc
        total = sum(dice_values)
        even_odd = total % 2  # 0: ch·∫µn, 1: l·∫ª

        # Th·ªëng k√™ t·ª´ l·ªãch s·ª≠
        count_tai = history.count("t")
        count_xiu = history.count("x")
        total_history = len(history)
        ratio_tai = count_tai / total_history if total_history > 0 else 0
        ratio_xiu = count_xiu / total_history if total_history > 0 else 0

        # D·ªØ li·ªáu ƒë·∫ßu v√†o cho m√¥ h√¨nh
        input_features = np.array([[total, even_odd, ratio_tai, ratio_xiu]])
        input_scaled = scaler.transform(input_features)  # Chu·∫©n h√≥a d·ªØ li·ªáu

        # D·ª± ƒëo√°n b·∫±ng voting model
        prob_voting = voting_model.predict_proba(input_scaled)[:, 1][0]
        prediction = "t" if prob_voting > 0.5 else "x"

        # T√≠nh x√°c su·∫•t cho t√†i/x·ªâu
        prob_tai = prob_voting * 100  # X√°c su·∫•t t√†i
        prob_xiu = (1 - prob_voting) * 100  # X√°c su·∫•t x·ªâu

        return prediction, prob_tai, prob_xiu
    except Exception as e:
        log_error(e)  # Ghi l·∫°i l·ªói ƒë·ªÉ debug
        return None, 0, 0  # Tr·∫£ v·ªÅ d·ª± ƒëo√°n m·∫∑c ƒë·ªãnh
# ==============================
# C√°c l·ªánh cho bot Telegram
# ==============================

# H√†m hu·∫•n luy·ªán m√¥ h√¨nh d∆∞·ªõi n·ªÅn
def background_training():
    while True:
        try:
            # Ti·∫øn h√†nh hu·∫•n luy·ªán m√¥ h√¨nh n·∫øu c√≥ ƒë·ªß d·ªØ li·ªáu
            if len(history_data) > 10:
                train_models()  # Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi d·ªØ li·ªáu hi·ªán t·∫°i
            time.sleep(60)  # Ch·∫°y l·∫°i m·ªói 60 gi√¢y ƒë·ªÉ hu·∫•n luy·ªán d∆∞·ªõi n·ªÅn
        except Exception as e:
            print(f"L·ªói khi hu·∫•n luy·ªán d∆∞·ªõi n·ªÅn: {e}")
            time.sleep(60)  # ƒê·ª£i tr∆∞·ªõc khi th·ª≠ l·∫°i
            
def start_background_training():
    training_thread = threading.Thread(target=background_training, daemon=True)
    training_thread.start()

# L·ªánh /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    load_data()
    await update.message.reply_text(
    "‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu th√†nh c√¥ng.\n"
    )
    start_background_training()  # Kh·ªüi ƒë·ªông hu·∫•n luy·ªán n·ªÅn
    await update.message.reply_text(
        "ü§ñ Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi bot T√†i/X·ªâu!\n"
        "S·ª≠ d·ª•ng c√°c l·ªánh sau ƒë·ªÉ b·∫Øt ƒë·∫ßu:\n"
        "- /tx <chu·ªói l·ªãch s·ª≠>: D·ª± ƒëo√°n d·ª±a tr√™n l·ªãch s·ª≠.\n"
        "- /txs <d√£y s·ªë>: D·ª± ƒëo√°n k·∫øt h·ª£p t·ª´ l·ªãch s·ª≠ v√† s√∫c s·∫Øc.\n"
        "- /add <l·ªãch s·ª≠ | s√∫c s·∫Øc>: Th√™m d·ªØ li·ªáu m·ªõi.\n"
        "- /history: Xem l·ªãch s·ª≠.\n"
        "- /help: H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng.\n"
    )

# L·ªánh /tx: D·ª± ƒëo√°n d·ª±a tr√™n l·ªãch s·ª≠
async def tx(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if len(context.args) != 1 or not context.args[0].strip():
            await update.message.reply_text("Vui l√≤ng nh·∫≠p ƒë√∫ng ƒë·ªãnh d·∫°ng: /tx xtxtxtxxxt.")
            return

        user_history = context.args[0].strip()
        if not all(item in ["t", "x"] for item in user_history):
            await update.message.reply_text("D·ªØ li·ªáu l·ªãch s·ª≠ ch·ªâ ƒë∆∞·ª£c ch·ª©a 't' (T√†i) ho·∫∑c 'x' (X·ªâu).")
            return

        # C·∫≠p nh·∫≠t d·ªØ li·ªáu l·ªãch s·ª≠
        history_data.extend(user_history)
        save_data()  # L∆∞u d·ªØ li·ªáu sau khi c·∫≠p nh·∫≠t

        prediction, prob_tai, prob_xiu = combine_predictions(list(history_data), dice_data)
        pattern = detect_pattern(list(history_data))

        buttons = InlineKeyboardMarkup([
            [InlineKeyboardButton("‚úÖ ƒê√∫ng", callback_data=f"correct|{prediction}"),
             InlineKeyboardButton("‚ùå Sai", callback_data=f"wrong|{prediction}")]
        ])
        await update.message.reply_text(
            f"D·ª± ƒëo√°n: {'T√†i' if prediction == 't' else 'X·ªâu'}\n"
            f"T·ª∑ l·ªá ph·∫ßn trƒÉm T√†i: {prob_tai:.2f}%\n"
            f"T·ª∑ l·ªá ph·∫ßn trƒÉm X·ªâu: {prob_xiu:.2f}%\n"
            f"Ph√°t hi·ªán c·∫ßu: {pattern}",
            reply_markup=buttons
        )
    except Exception as e:
        await update.message.reply_text(f"ƒê√£ x·∫£y ra l·ªói: {e}")

# L·ªánh /txs
async def txs(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        if len(context.args) == 0:
            await update.message.reply_text("Vui l√≤ng nh·∫≠p ƒë√∫ng ƒë·ªãnh d·∫°ng: /txs 15 5 8 9 10.")
            return

        try:
            dice_values = list(map(int, context.args))
            if not all(1 <= value <= 18 for value in dice_values):
                await update.message.reply_text("D·ªØ li·ªáu x√∫c x·∫Øc ch·ªâ ƒë∆∞·ª£c ch·ª©a c√°c s·ªë t·ª´ 1 ƒë·∫øn 18.")
                return
        except ValueError:
            await update.message.reply_text("D·ªØ li·ªáu x√∫c x·∫Øc ph·∫£i l√† c√°c s·ªë nguy√™n c√°ch nhau b·ªüi d·∫•u c√°ch.")
            return

        # C·∫≠p nh·∫≠t d·ªØ li·ªáu x√∫c x·∫Øc
        dice_data.extend(dice_values)
        save_data()  # L∆∞u d·ªØ li·ªáu sau khi c·∫≠p nh·∫≠t

        prediction, prob_tai, prob_xiu = combine_predictions(list(history_data), dice_data)
        pattern = detect_pattern(list(history_data))

        buttons = InlineKeyboardMarkup([
            [InlineKeyboardButton("‚úÖ ƒê√∫ng", callback_data=f"correct|{prediction}"),
             InlineKeyboardButton("‚ùå Sai", callback_data=f"wrong|{prediction}")]
        ])
        await update.message.reply_text(
            f"D·ª± ƒëo√°n: {'T√†i' if prediction == 't' else 'X·ªâu'}\n"
            f"T·ª∑ l·ªá ph·∫ßn trƒÉm T√†i: {prob_tai:.2f}%\n"
            f"T·ª∑ l·ªá ph·∫ßn trƒÉm X·ªâu: {prob_xiu:.2f}%\n"
            f"Ph√°t hi·ªán c·∫ßu: {pattern}",
            reply_markup=buttons
        )
    except Exception as e:
        await update.message.reply_text(f"ƒê√£ x·∫£y ra l·ªói: {e}")
        
async def add(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        user_input = ' '.join(context.args)
        if not user_input:
            await update.message.reply_text("Vui l√≤ng nh·∫≠p d·ªØ li·ªáu d·∫°ng: 't x t | 15 10 9'.")
            return

        # T√°ch l·ªãch s·ª≠ v√† s√∫c s·∫Øc
        parts = user_input.split("|")
        if len(parts) != 2:
            await update.message.reply_text("D·ªØ li·ªáu kh√¥ng h·ª£p l·ªá! Nh·∫≠p d·∫°ng 't x t | 15 10 9'.")
            return

        # X·ª≠ l√Ω l·ªãch s·ª≠
        history = parts[0].strip().split()
        if not all(item in ["t", "x"] for item in history):
            await update.message.reply_text("L·ªãch s·ª≠ ch·ªâ ƒë∆∞·ª£c ch·ª©a 't' (T√†i) ho·∫∑c 'x' (X·ªâu).")
            return

        # X·ª≠ l√Ω d·ªØ li·ªáu s√∫c s·∫Øc
        try:
            dice_values = list(map(int, parts[1].strip().split()))
        except ValueError:
            await update.message.reply_text("D·ªØ li·ªáu s√∫c s·∫Øc ph·∫£i l√† s·ªë nguy√™n, c√°ch nhau b·ªüi d·∫•u c√°ch.")
            return

        # Th√™m v√†o b·ªô nh·ªõ
        history_data.extend(history)
        dice_data.extend(dice_values)

        await update.message.reply_text("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c th√™m th√†nh c√¥ng!")
    except Exception as e:
        await update.message.reply_text(f"ƒê√£ x·∫£y ra l·ªói: {e}")
        
# L·ªánh /history: Xem l·ªãch s·ª≠
async def history(update: Update, context: ContextTypes.DEFAULT_TYPE):
    history_str = ', '.join(history_data)
    dice_str = ', '.join(map(str, dice_data))
    await update.message.reply_text(
        f"L·ªãch s·ª≠ T√†i/X·ªâu: {history_str}\nL·ªãch s·ª≠ S√∫c s·∫Øc: {dice_str}"
    )

# ==============================
# X·ª≠ l√Ω callback cho n√∫t ƒê√∫ng/Sai
# ==============================

async def handle_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    await query.answer()

    data = query.data.split("|")
    action = data[0]
    prediction = data[1]

    if action == "correct":
        history_data.append(prediction)
        await query.edit_message_text("C·∫£m ∆°n! K·∫øt qu·∫£ ƒë√£ ƒë∆∞·ª£c x√°c nh·∫≠n v√† l∆∞u l·∫°i.")
    elif action == "wrong":
        await query.edit_message_text("C·∫£m ∆°n! K·∫øt qu·∫£ s·∫Ω kh√¥ng ƒë∆∞·ª£c l∆∞u l·∫°i.")

async def help(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng bot:\n"
        "1. **/tx <chu·ªói l·ªãch s·ª≠>**: D·ª± ƒëo√°n k·∫øt qu·∫£ d·ª±a tr√™n l·ªãch s·ª≠ T√†i/X·ªâu.\n"
        "   V√≠ d·ª•: /tx t x t x\n"
        "2. **/txs <d√£y s·ªë s√∫c s·∫Øc>**: D·ª± ƒëo√°n k·∫øt h·ª£p l·ªãch s·ª≠ v√† d√£y s·ªë s√∫c s·∫Øc.\n"
        "3. **/add <l·ªãch s·ª≠ ho·∫∑c s√∫c s·∫Øc>**: Th√™m d·ªØ li·ªáu v√†o l·ªãch s·ª≠.\n"
        "4. **/history**: Xem l·ªãch s·ª≠ T√†i/X·ªâu v√† s√∫c s·∫Øc.\n"
    )

# =============================
# Ch·∫°y bot
# =============================

if __name__ == "__main__":
    app = ApplicationBuilder().token(TOKEN).build()

    # Th√™m c√°c l·ªánh v√†o bot
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help))  # Th√™m l·ªánh /help
    app.add_handler(CommandHandler("tx", tx))
    app.add_handler(CommandHandler("txs", txs))
    app.add_handler(CommandHandler("add", add))
    app.add_handler(CommandHandler("history", history))
    app.add_handler(CallbackQueryHandler(handle_callback))

    print("Bot ƒëang ch·∫°y...")
    app.run_polling()